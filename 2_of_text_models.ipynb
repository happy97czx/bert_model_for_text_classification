{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 of text  models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Two models Bert and BiLSTM"
      ],
      "metadata": {
        "id": "naHAfMFe8Oeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "import tez\n",
        "from sklearn import metrics, model_selection\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "NXJHTqyxXCTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tez\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "LwQRflOGWv3Y",
        "outputId": "10269aee-a3ad-42f5-9570-a66bba4dbba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tez\n",
            "  Downloading tez-0.6.5-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: tez\n",
            "Successfully installed tez-0.6.5\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=fdacd67da5defffa3f06814ad1f759f8e12dcf08e07f81b1b318f7b394bd22cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "class BERTDataset:\n",
        "    def __init__(self, review, target):\n",
        "        self.review = review\n",
        "        self.target = target\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "        self.max_len = 64\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.review)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        review = str(self.review[item])\n",
        "        review = \" \".join(review.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"targets\": torch.tensor(self.target[item], dtype=torch.float),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "giD0LmDPWkqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTBaseUncased(tez.Model):\n",
        "    def __init__(self, num_train_steps):\n",
        "        super().__init__()\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\", return_dict=False)\n",
        "        self.bert_drop = nn.Dropout(0.5)\n",
        "        self.out = nn.Linear(768, 1)\n",
        "        self.num_train_steps = num_train_steps\n",
        "        self.step_scheduler_after = \"batch\"\n",
        "\n",
        "    def fetch_optimizer(self):\n",
        "        param_optimizer = list(self.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\"]\n",
        "        optimizer_parameters = [{\n",
        "                \"params\": [\n",
        "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "                ],\n",
        "                \"weight_decay\": 0.001,}\n",
        "        ]\n",
        "        opt = AdamW(optimizer_parameters, lr=3e-5)\n",
        "        return opt\n",
        "\n",
        "    def fetch_scheduler(self):\n",
        "        sch = get_linear_schedule_with_warmup(\n",
        "            self.optimizer, num_warmup_steps=0, num_training_steps=self.num_train_steps\n",
        "        )\n",
        "        return sch\n",
        "\n",
        "    def loss(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return None\n",
        "        return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "    def monitor_metrics(self, outputs, targets):\n",
        "        if targets is None:\n",
        "            return {}\n",
        "        outputs = torch.sigmoid(outputs).cpu().detach().numpy() >= 0.5\n",
        "        targets = targets.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        return {\"accuracy\": accuracy}\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids, targets=None):\n",
        "        _, out = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "        outp = self.bert_drop(out)\n",
        "        output = self.out(outp)\n",
        "        loss = self.loss(output, targets)\n",
        "        acc = self.monitor_metrics(output, targets)\n",
        "        return output, loss, acc\n"
      ],
      "metadata": {
        "id": "gxypLgLNWmah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset( review=train_df.review.values, target=train_df.sentiment.values)\n",
        "valid_dataset = BERTDataset(review=valid_df.review.values, target=valid_df.sentiment.values)\n",
        "\n",
        "n_train_steps = int(len(train_df) / 32 * 10)\n",
        "model = BERTBaseUncased(num_train_steps=n_train_steps)\n",
        "\n",
        "es = tez.callbacks.EarlyStopping(monitor=\"valid_loss\", model_path=\"model.bin\")\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    valid_dataset=valid_dataset,\n",
        "    train_bs=64,\n",
        "    device=\"cuda\",\n",
        "    epochs=50,\n",
        "    callbacks=[es],\n",
        "    fp16=True,\n",
        ")\n",
        "model.save(\"model.bin\")"
      ],
      "metadata": {
        "id": "ct9SYmiTWo3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM"
      ],
      "metadata": {
        "id": "lSaeYasx8YYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
      ],
      "metadata": {
        "id": "kajp5q-gh_Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " n_unique_words = 10000 # cut texts after this number of words\n",
        " maxlen = 200\n",
        " batch_size = 128"
      ],
      "metadata": {
        "id": "jpo950_kmJhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zeugma"
      ],
      "metadata": {
        "id": "UPivyVZzoZ02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zeugma.embeddings import EmbeddingTransformer"
      ],
      "metadata": {
        "id": "qpSzglIiozWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = EmbeddingTransformer('glove')\n",
        "x2 = glove.transform(df.reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNKpGupVoi-a",
        "outputId": "67f3da73-0f28-45b1-9b6e-81637f0d1e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.api:Creating /root/gensim-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:gensim.api:glove-twitter-25 downloaded\n",
            "INFO:gensim.models.utils_any2vec:loading projection weights from /root/gensim-data/glove-twitter-25/glove-twitter-25.gz\n",
            "INFO:gensim.models.utils_any2vec:loaded (1193514, 25) matrix from /root/gensim-data/glove-twitter-25/glove-twitter-25.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x2\n",
        "y = df.sentiment\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "N2kJfTfLmNbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        " x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        " y_train = np.array(y_train)\n",
        " y_test = np.array(y_test) "
      ],
      "metadata": {
        "id": "Q-TKJvl7mkWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model = Sequential()\n",
        " model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
        " model.add(Bidirectional(LSTM(64)))\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Dense(1, activation='sigmoid'))\n",
        " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv5fh9OumVda",
        "outputId": "3d4cd2bf-8d95-437c-b0fa-92415d8c52ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " history=model.fit(x_train, y_train,\n",
        "           batch_size=256,\n",
        "           epochs=2,\n",
        "           validation_data=[x_test, y_test])\n",
        " print(history.history['loss'])\n",
        " print(history.history['accuracy']) "
      ],
      "metadata": {
        "id": "cyk9jIrAmV_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from matplotlib import pyplot\n",
        " pyplot.plot(history.history['loss'])\n",
        " pyplot.plot(history.history['accuracy'])\n",
        " pyplot.title('model loss vs accuracy')\n",
        " pyplot.xlabel('epoch')\n",
        " pyplot.legend(['loss', 'accuracy'], loc='upper right')\n",
        " pyplot.show() "
      ],
      "metadata": {
        "id": "JSWaXfV-mdDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_report(labels, preds):\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    precision = (tp)/(tp+fp)\n",
        "    recall = (tp)/(tp+fn)\n",
        "    f1 = (2*(precision*recall))/(precision+recall)\n",
        "    return {\n",
        "        \"mcc\": mcc,\n",
        "        \"true positive\": tp,\n",
        "        \"true negative\": tn,\n",
        "        \"false positive\": fp,\n",
        "        \"false negative\": fn,\n",
        "        \"pricision\" : precision,\n",
        "        \"recall\" : recall,\n",
        "        \"F1\" : f1,\n",
        "        \"accuracy\": (tp+tn)/(tp+tn+fp+fn)\n",
        "    }\n",
        "def compute_metrics(labels, preds):\n",
        "    assert len(preds) == len(labels)\n",
        "    return get_eval_report(labels, preds)\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "t0AollwXg-j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ],
      "metadata": {
        "id": "xBtVMnIahOBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Evaluating Model ... \\n\")\n",
        "predicted = model.predict_classes(x_test)\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "print(\"\\n\")\n",
        "logger = logging.getLogger(\"logger\")\n",
        "result = compute_metrics(y_test, predicted)\n",
        "for key in (result.keys()):\n",
        "    logger.info(\"  %s = %s\", key, str(result[key]))"
      ],
      "metadata": {
        "id": "F1lw8HiIhS8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D5uji3BVqfec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}